---
title: "J-Study manuscript"
author: "Monica Thieu"
date: "Updated `r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
require(targets)
require(tidyverse)
require(magrittr)
require(rlang)
# source(here::here("R", "get_cleaned_data.R"))
# load(here::here("ignore", "data", "preplots.rda")) # For the model params
# load(here::here("ignore", "data", "plots_ms.rda"))

target_store <- here::here("ignore", "_targets")
signif_digits <- 3L
```

```{r setup-extra-stat-reports}
summarize_kable <- function (data,
                               col,
                               digs = signif_digits,
                               fn_list = list(mean = \(x) mean(x, na.rm = T),
                                              sd = \(x) sd(x, na.rm = T))) {
  data %>% 
    summarize(across({{col}}, fn_list)) %>% 
    mutate(across(where(is.numeric), \(x) signif(x, digits = digs))) %>% 
    knitr::kable()
}
```


# Figures and captions

## Figure 3

```{r}
q_google_demos <- tar_read(q_google_demos, store = target_store)
j_exp <- tar_read(expertise_summarized, store = target_store)
plot_demos <- tar_read(plot_demos, store = target_store) +
  theme_ms +
  theme(legend.position = c(1, 1),
          legend.justification = c(1, 1)) 
plot_expertise_hist <- tar_read(plot_expertise_hist, store = target_store) +
  theme_ms
```

```{r figure-3}
knitr::include_graphics(here::here("ignore", "figs", "ms_fig3.png"))
```

## Figure 4

```{r}
knitr::include_graphics(here::here("ignore", "figs", "ms_fig4.png"))
```

## Figure 5

```{r}
knitr::include_graphics(here::here("ignore", "figs", "ms_fig5.png"))
# Question from Chris at Alyssano CNS practice lab meeting March 10 2023: Were trivia experts more likely to report certain facts as novel? (like, ones that might be harder)
```

# Stats to copy and paste

Or to inject if I can figure out a better way that preserves the Google-Docsery...

## Demographics

Number of participants: `r nrow(q_google_demos)`

Participants breakdown by gender:

```{r}
q_google_demos %>% 
  count(gender) %>% 
  knitr::kable()
```

Participant summary by age:

```{r}
q_google_demos %>% 
  summarize_kable(age)
```

## Task info

Encoding trial duration:

```{r}
encoding <- tar_read(encoding, store = target_store)

encoding %>%
  # there is literally _one_ trial where the timing seems to have messed up and run over
  filter(rt <= 35100) %>% 
  mutate(rt = rt / 1000) %>% 
  summarize_kable(rt)
```

Expertise score:

```{r}
j_exp %>% 
  # to get it in units of questions
  mutate(j_score = j_score * 50) %>% 
  summarize_kable(j_score,
                  fn_list = list(min = \(x) min(x, na.rm = T),
                                 max = \(x) max(x, na.rm = T),
                                 median = \(x) median(x, na.rm = T)))
```

Number of novel facts at encoding:

```{r}
encoding %>% 
  filter(already_knew == "none") %>% 
  count(subj_num) %>% 
  summarize_kable(n,
                  digs = 2L,
                  fn_list = list(min = \(x) min(x, na.rm = T),
                                 mean = \(x) mean(x, na.rm = T),
                                 sd = \(x) sd(x, na.rm = T)))
```

## Major results

### Encoding

Beta median/CIs from the model with **interest** as the outcome variable.

Note: For this model, effective N failed to reach 10% of the sampling iterations for several parameters, even after increasing the number of sampling iterations to 3000 iterations/chain. However, no other associated model reliability parameters (like Rhat) suggested concern. We thus report these model outcomes as is. We expect that some of the apparently low N~eff~ may arise from individual participants having different distributions of interst ratings across their facts.

```{r}
fn_list_model.coefs <- list(q025 = \(x) quantile(x, .025),
                            q500 = \(x) median(x, na.rm = T),
                            q975 = \(x) quantile(x, .975))

tar_read(preplot_params_interest, store = target_store) %>%
  group_by(term) %>% 
  summarize_kable(estimate,
                  fn_list = fn_list_model.coefs)
```

Beta median/CIs from the model with **prior knowledge** as the outcome variable. Should be encoded with none as 0 and some/all as 1.

```{r}
tar_read(preplot_params_alreadyknew, store = target_store) %>%
  group_by(term) %>% 
  summarize_kable(estimate,
                  fn_list = fn_list_model.coefs)
```


### Retrieval

#### Beta medians & CIs

Beta median/CIs from the model with **photo memory** as the outcome variable

```{r}
tar_read(preplot_params_pic, store = target_store) %>%
  group_by(term) %>% 
  summarize_kable(estimate,
                  fn_list = fn_list_model.coefs)
```

Beta median/CIs from the model with **museum memory** as the outcome variable

```{r}
tar_read(preplot_params_source, store = target_store) %>%
  group_by(term) %>% 
  summarize_kable(estimate,
                  fn_list = fn_list_model.coefs)
```


Beta medians/CIs from the **omnibus model**

```{r}
preplot_params_fact_by_both <- tar_read(preplot_params_fact_by_both, store = target_store) 

preplot_params_fact_by_both %>%
  group_by(term) %>% 
  summarize_kable(estimate,
                  fn_list = fn_list_model.coefs)
```

#### Omnibus model simple effects

"low" trivia expertise for the preplots is j_score = -2, while "high" trivia expertise is +1

```{r}
preplot_params_fact_by_both %>% 
  filter(term %in% c("resp_pic:resp_source", "resp_pic:resp_source:j_score")) %>% 
  mutate(term = str_replace_all(term, ":", ".")) %>% 
  pivot_wider(names_from = term,
              values_from = estimate) %>% 
  mutate(low = resp_pic.resp_source - 2*resp_pic.resp_source.j_score,
         high = resp_pic.resp_source + resp_pic.resp_source.j_score) %>% 
  select(iteration, low, high) %>% 
  pivot_longer(cols = c(low, high),
               names_to = "j_score",
               values_to = "estimate") %>% 
  group_by(j_score) %>% 
  summarize_kable(estimate,
                  fn_list = fn_list_model.coefs)
```

```{r}
preplot_fixef_fact_by_both %>% 
  group_by(j_score, resp_pic, resp_source) %>% 
  summarize_kable(acc_pred,
                  fn_list = list(median = median))
```

