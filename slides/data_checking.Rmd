---
title: "Exploratory data analysis"
subtitle: "J-Study"
author: "Monica Thieu & Lauren Wilkins"
institute: "Columbia University Dept of Psychology"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE)

source(here::here("R", "get_cleaned_data.R"))
```

# Demographics

What is the age and gender breakdown?

```{r}
q_google_demos %>% 
  ggplot(aes(x = age, fill = gender)) +
  geom_histogram(position = "identity", alpha = 0.5, binwidth = 2)
```


# Trivia expertise assessment

What is our sample spread of trivia expertise?

```{r}
j_exp %>% 
  ggplot(aes(x = j_score)) +
  geom_histogram(binwidth = .05) +
  geom_vline(xintercept = 0.7, linetype = "dotted") +
  labs(x = "Expertise score")
```

Are men and women participants balanced on trivia expertise?

```{r}
j_exp %>% 
  mutate(subj_num = factor(subj_num)) %>% 
  left_join(q_google_demos, by = "subj_num") %>% 
  ggplot(aes(x = j_score, fill = gender)) +
  geom_histogram(binwidth = .05, position = "identity", alpha = 0.5) +
  geom_vline(xintercept = 0.7, linetype = "dotted") +
  labs(x = "Expertise score")
```

Do older participants know more trivia?

```{r}
j_exp %>% 
  mutate(subj_num = factor(subj_num)) %>% 
  left_join(q_google_demos, by = "subj_num") %>% 
  ggplot(aes(x = age, y = j_score)) +
  geom_point() +
  geom_smooth(method = "lm") +
  geom_hline(yintercept = 0.7, linetype = "dotted") +
  labs(y = "Expertise score")
```

Do Ps accurately assess their own trivia skill?

```{r}
q_trivia_demos %>% 
  left_join(q_google_demos, by = "subj_num") %>% 
  ggplot(aes(x = trivia_skill_self, y = j_score)) +
  # geom_abline(slope = .01, intercept = 0, linetype = "dotted") +
  geom_vline(xintercept = 75, linetype = "dotted") +
  geom_hline(yintercept = 0.7, linetype = "dotted") +
  geom_point(aes(color = gender), size = 2, alpha = 0.7) +
  geom_smooth(method = "lm", formula = y ~ x) +
  expand_limits(y = 0) +
  labs(x = "Self-reported trivia expertise (relative to 'average person')",
       y = "Expertise score on Jeopardy audition test") +
  theme_bw()
```

```{r}
j_recall %>% 
  mutate(resp_conf = coalesce(resp_conf, 0), 
         resp_conf_bin = cut_interval(resp_conf, length = 25, labels = FALSE)) %>% 
  group_by(subj_num, j_score, resp_conf_bin) %>% 
  summarize(acc = mean(acc_recall), n_trials = n()) %>% 
  ggplot(aes(x = resp_conf_bin, y = acc, color = j_score)) + 
  geom_line(aes(group = subj_num), alpha = 0.5) + 
  geom_point(aes(size = n_trials), alpha = 0.5) + 
  scale_color_viridis_c()
```

## Trivia recall by confidence

I still haven't sorted out the best way to think about this, or how important it really is, we see a vaguely Dunning-Krugery effect where participants with lower overall scores tend to be more wrong at higher confidence.

```{r}
j_recall %>% 
  ggplot(aes(x = resp_conf, y = as.integer(acc_recall), color = j_score, fill = j_score)) + 
  geom_jitter(alpha = 0.3, height = 0.05) + 
  geom_smooth(aes(group = subj_num), method = "glm", method.args = list(family = "binomial"), se = FALSE) + 
  scale_color_viridis_c() +
  scale_fill_viridis_c() +
  labs(x = "Recall confidence",
       y = "Recall accuracy (strict)",
       color = "Expertise score",
       fill = "Expertise score") +
  theme_bw()
```

## Trivia recall metamemory

Metamemory state counts (correct trials only!)

```{r}
j_meta %>%
  filter(!is.na(resp)) %>% 
  left_join(j_recall %>% select(subj_num, answer, acc_recall)) %>% 
  filter(acc_recall) %>% 
  ggplot(aes(x = subj_num, fill = resp)) +
  geom_bar() +
  labs(x = "Participant", y = "# correctly recalled facts labeled with that memory state", fill = "Memory state") +
  theme_bw() +
  theme(axis.text.x = element_blank(),
        legend.position = 0:1,
        legend.justification = 0:1,
        legend.background = element_blank())
```

Recall accuracy by metamemory state

```{r}
j_recall %>%
  select(subj_num, j_score, question, answer, acc_recall) %>%
  left_join(j_meta %>% select(subj_num, question, answer, metamemory = resp),
            by = c("subj_num", "question", "answer")) %>%
  mutate(metamemory = coalesce(metamemory, "Don't Know")) %>%
  group_by(subj_num, metamemory) %>%
  summarize(acc = mean(acc_recall),
            n_trials = n()) %>%
  ggplot(aes(x = metamemory, y = acc)) +
  geom_boxplot()
```

Metamemory state relative percentages

```{r}
j_meta %>%
  left_join(j_recall %>% select(subj_num, answer, acc_recall)) %>% 
  filter(acc_recall) %>% 
  count(subj_num, resp) %>% 
  group_by(subj_num) %>% 
  mutate(prob = n / sum(n)) %>% 
  ggplot(aes(x = subj_num, y = prob, fill = resp)) +
  geom_col() +
  labs(x = "Participant", y = "Percent facts labeled with that memory state", fill = "Memory state") +
  theme_bw() +
  theme(axis.text.x = element_blank())
```

# Self-report measures

```{r}
q_trivia_demos %>%
  select(subj_num, starts_with("trivia"), j_score) %>% 
  mutate(j_score = j_score * 100) %>% 
  pivot_longer(cols = -subj_num, names_to = "var", values_to = "value") %>% 
  ggplot(aes(x = value)) + 
  geom_histogram() + 
  facet_wrap(~ var)
```

# Museum task encoding

How many people got which categories?

```{r}
encoding %>% 
  distinct(subj_num, group, category) %>% 
  mutate(category = fct_relevel(category, "arms", "gems", "musi")) %>% 
  ggplot(aes(x = group, fill = category)) +
  geom_bar() +
  geom_text(aes(label = category), stat = "count", vjust = 1.5, colour = "white") +
  theme(legend.position = 0:1, legend.justification = 0:1, legend.background = element_blank())
```

???

Check whether category assignment is related to expertise

Are some categories more interesting than others?

```{r}
encoding %>% 
  group_by(group_trial_num, category) %>% 
  summarize(interest_mean = mean(resp), interest_sd = sd(resp)) %>% 
  ggplot(aes(x = interest_mean, fill = category)) +
  geom_density(alpha = 0.5) +
  labs(x = "Mean (across Ps) interest rating for each fact") +
  theme(legend.position = 0:1,
        legend.justification = 0:1,
        legend.background = element_blank(),
        legend.direction = "horizontal")
```

Are trivia experts more interested overall?

```{r}
encoding %>% 
  group_by(subj_num, j_score) %>% 
  summarize(resp = median(resp)) %>% 
  ggplot(aes(x = j_score, y = resp)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x = "Expertise score",
       y = "P's median interest (across facts)")
```

```{r}
encoding %>% 
  ggplot(aes(x = subj_num, fill = fct_rev(already_knew))) +
  geom_bar() +
  geom_hline(yintercept = 40, linetype = "dotted") +
  scale_x_discrete(guide = guide_axis(angle = 30)) +
  labs(x = "Participant (expertise low to high)", y = "# facts already knew", fill = "Prior knowledge") +
  theme_bw() +
  theme(axis.text.x = element_blank())
```

# Museum task retrieval

## Fact recall by question order/chunk type

```{r}
retrieval_temp <- retrieval %>% 
  nest(data = -subj_num) %>% 
  slice_sample(n = 8) %>% 
  unnest(data)

retrieval_temp %>% 
  ggplot(aes(x = retrieval_trial_num, y = acc_recall)) +
  geom_rect(aes(x = NULL, y = NULL, xmin = xmin, xmax = xmax, fill = retrieval_block_type),
            data = retrieval_temp %>%
              select(subj_num, retrieval_block, retrieval_trial_num, retrieval_block_type) %>%
              group_by(subj_num, retrieval_block) %>%
              filter(retrieval_trial_num %in% range(retrieval_trial_num)) %>%
              mutate(xtype = if_else(retrieval_trial_num == min(retrieval_trial_num), "xmin", "xmax")) %>%
              ungroup() %>%
              pivot_wider(names_from = xtype, values_from = retrieval_trial_num) %>% 
              mutate(xmin = xmin - 0.5,
                     xmax = xmax + 0.5),
            ymin = 0, ymax = 1, alpha = 0.5) +
  geom_line() +
  geom_point(aes(color = already_knew)) +
  # scale_colour_viridis_b() +
  scale_y_continuous(n.breaks = 3) +
  facet_grid(subj_num ~ .) +
  labs(x = "Fact recall trial (beginning to end)", y = "Fact recall accuracy", fill = "Chunk type") +
  theme_bw()
```

## Fact recall by chunk type

Now filtered to include only not-previously-known facts

```{r}
retrieval %>% 
  filter(already_knew == "none") %>% 
  mutate(ep_is_same = recode(ep_is_same,
                                         `0` = "ep diff",
                                         `1` = "ep same"),
                     sem_is_same = recode(sem_is_same,
                                          `0` = "sem diff",
                                          `1` = "sem same")) %>% 
  group_by(subj_num, j_score, ep_is_same, sem_is_same) %>% 
  summarize(mean_acc = mean(acc_recall)) %>% 
  ggplot(aes(x = interaction(ep_is_same, sem_is_same), y = mean_acc,
             group = subj_num,
             color = j_score)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(guide = guide_axis(angle = 30)) +
  scale_color_viridis_c() +
  labs(x = "Chunk type", y = "Percent facts correctly recalled", color = "Expertise score") +
  theme_bw()
```

???

Fix this graph to filter for didn't already know

Look at RT measures as a function of chunk type! Difference between start and finish normalized by answer length?

## Is recall higher when people already know (some of) the facts?

```{r}
retrieval %>% 
  filter(!is.na(already_knew)) %>% 
  group_by(subj_num, already_knew) %>% 
  summarize(acc_recall = mean(acc_recall)) %>% 
  ggplot(aes(x = already_knew, y = acc_recall)) +
  geom_violin() +
  labs(x = "Fact prior knowledge at encoding", y = "% correct recall")
```

## Photo recognition

A-A' 2AFC with similar lure

```{r}
this_cor <- r_pics %>%
  group_by(subj_num, j_score) %>% 
  summarize(acc = mean(resp)) %$% 
  cor(j_score, acc) %>% 
  round(2)
```

```{r}
r_pics %>%
  group_by(subj_num, j_score) %>% 
  summarize(acc = mean(resp)) %>% 
  ggplot(aes(x = j_score, y = acc)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x = "Expertise score", y = "Mean accuracy WITH confidence (-50 to 50)",
       title = paste("Pearson correlation:", this_cor))
```

## Photo recognition

A-A' 2AFC with similar lure

```{r}
this_cor <- r_pics %>%
  group_by(subj_num, j_score) %>% 
  summarize(acc = mean(resp_binary)) %$% 
  cor(j_score, acc) %>% 
  round(2)
```

```{r}
r_pics %>%
  group_by(subj_num, j_score) %>% 
  summarize(acc = mean(resp_binary)) %>% 
  ggplot(aes(x = j_score, y = acc)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x = "Expertise score", y = " Mean accuracy WITHOUT confidence (0 to 1)",
       title = paste("Pearson correlation:", this_cor))
```

## Source memory for which museum

```{r}
this_cor <- r_source %>%
  group_by(subj_num, j_score) %>% 
  summarize(acc = mean(resp)) %$% 
  cor(j_score, acc) %>% 
  round(2)
```

```{r}
r_source %>%
  group_by(subj_num, j_score) %>% 
  summarize(acc = mean(resp)) %>% 
  ggplot(aes(x = j_score, y = acc)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x = "Expertise score", y = " Mean accuracy WITH confidence (-50 to 50)",
       title = paste("Pearson correlation:", this_cor))
```

```{r}
this_cor <- r_source %>%
  group_by(subj_num, j_score) %>% 
  summarize(acc = mean(resp_binary)) %$% 
  cor(j_score, acc) %>% 
  round(2)
```

```{r}
r_source %>%
  group_by(subj_num, j_score) %>% 
  summarize(acc = mean(resp_binary)) %>% 
  ggplot(aes(x = j_score, y = acc)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x = "Expertise score", y = " Mean accuracy WITHOUT confidence (0 to 1)",
       title = paste("Pearson correlation:", this_cor))
```

---

class: inverse, middle

# Retrieval between-task relationships

---

## Does _photo_ retrieval predict _fact_ retrieval?

```{r}
retrieval %>% 
  filter(already_knew == "none") %>% 
  mutate(acc_recall = if_else(acc_recall == 0.5, 1, acc_recall)) %>%
  ggplot(aes(x = resp_pic, y = acc_recall, color = cut_number(j_score, 3), fill = cut_number(j_score, 3))) + 
  geom_jitter(alpha = 0.3, height = 0.05) + 
  geom_smooth( method = "glm", method.args = list(family = "binomial"), alpha = 0.2) + 
  labs(x = "Photo recognition accuracy",
       y = "Fact recall accuracy (generous)",
       color = "Expertise tertile",
       fill = "Expertise tertile") +
  theme(legend.position = c(0, 0.75),
        legend.justification = c(0, 0.75),
        legend.background = element_blank())
```

???

Sanity check these against the apparent effect where high experts seem to be doing worse on photo memory?

```{r}
retrieval %>% 
  filter(already_knew == "none") %>% 
  mutate(acc_recall = as.numeric(acc_recall > 0),
         resp_pic = resp_pic / 100,
         j_score = j_score - 0.7) %>% 
  lme4::glmer(acc_recall ~ resp_pic * j_score + (1 + resp_pic | subj_num), data = ., family = "binomial") %>%
  summary()
```

## Does _source_ retrieval predict _fact_ retrieval?

```{r}
retrieval %>% 
  filter(already_knew == "none") %>% 
  mutate(acc_recall = if_else(acc_recall == 0.5, 1, acc_recall)) %>%
  ggplot(aes(x = resp_source,
             y = acc_recall,
             color = cut_number(j_score, 3),
             fill = cut_number(j_score, 3))) + 
  geom_jitter(alpha = 0.3, height = 0.05) + 
  geom_smooth( method = "glm", method.args = list(family = "binomial"), alpha = 0.2) + 
  labs(x = "Source recognition accuracy",
       y = "Fact recall accuracy (generous)",
       color = "Expertise tertile",
       fill = "Expertise tertile") +
  theme(legend.position = c(0, 0.75),
        legend.justification = c(0, 0.75),
        legend.background = element_blank())
```

???

Sanity check this one as well

```{r}
retrieval %>% 
  filter(already_knew == "none") %>% 
  mutate(acc_recall = as.numeric(acc_recall > 0),
         resp_source = resp_source / 100,
         j_score = j_score - 0.7) %>% 
  lme4::glmer(acc_recall ~ resp_source * j_score + (1 + resp_source | subj_num),
              data = ., family = "binomial") %>% 
  summary()
```

## Does _source_ retrieval predict _photo_ retrieval?

```{r}
retrieval %>% 
  filter(already_knew == "none") %>% 
  ggplot(aes(x = resp_source, y = resp_pic, color = cut_number(j_score, 3), fill = cut_number(j_score, 3))) +
  geom_point(alpha = 0.1) + 
  geom_smooth( method = "lm", alpha = 0.2) + 
  labs(x = "Source recognition accuracy",
       y = "Photo recognition accuracy",
       color = "Expertise tertile",
       fill = "Expertise tertile") +
  theme(legend.position = c(0, 0.5),
        legend.justification = c(0, 0.5),
        legend.background = element_blank())
```

```{r}
retrieval %>% 
  filter(already_knew == "none") %>% 
  mutate(resp_pic = resp_pic / 100,
         resp_source = resp_source / 100,
         j_score = j_score - 0.7) %>% 
  lme4::lmer(resp_pic ~ resp_source * j_score + (1 + resp_source | subj_num),
              data = .) %>% 
  summary()
```

## Does interest at encoding predict _fact_ retrieval?

```{r}
retrieval %>% 
  filter(already_knew == "none") %>% 
  mutate(acc_recall = if_else(acc_recall == 0.5, 1, acc_recall)) %>%
  ggplot(aes(x = interest, y = acc_recall, color = cut_number(j_score, 3), fill = cut_number(j_score, 3))) + 
  geom_jitter(alpha = 0.3, height = 0.05) + 
  geom_smooth( method = "glm", method.args = list(family = "binomial"), alpha = 0.2) + 
  labs(x = "Interest in fact at encoding",
       y = "Fact recall accuracy (generous)",
       color = "Expertise tertile",
       fill = "Expertise tertile") +
  theme(legend.position = c(0, 0.75),
        legend.justification = c(0, 0.75),
        legend.background = element_blank())
```

???

Include interest in the other models

## Does interest at encoding predict _photo_ retrieval?

```{r}
retrieval %>% 
  filter(already_knew == "none") %>% 
  ggplot(aes(x = interest, y = resp_pic, color = cut_number(j_score, 3), fill = cut_number(j_score, 3))) + 
  geom_point(alpha = 0.1) + 
  geom_smooth(method = "lm", alpha = 0.2) + 
  labs(x = "Interest in fact at encoding",
       y = "Photo recognition accuracy",
       color = "Expertise tertile",
       fill = "Expertise tertile") +
  theme(legend.position = c(0, 0.5),
        legend.justification = c(0, 0.5),
        legend.background = element_blank())
```

## Does interest at encoding predict _source_ retrieval?

```{r}
retrieval %>% 
  filter(already_knew == "none") %>% 
  ggplot(aes(x = interest, y = resp_source, color = cut_number(j_score, 3), fill = cut_number(j_score, 3))) + 
  geom_point(alpha = 0.1) + 
  geom_smooth(method = "lm", alpha = 0.2) + 
  labs(x = "Interest in fact at encoding",
       y = "Source recognition accuracy",
       color = "Expertise tertile",
       fill = "Expertise tertile") +
  theme(legend.position = c(0, 0.5),
        legend.justification = c(0, 0.5),
        legend.background = element_blank())
```
